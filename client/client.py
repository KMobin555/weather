import asyncio
import os
import json 
import sys

from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from google import genai
from google.genai import types
from google.genai.types import Tool, FunctionDeclaration
from google.genai.types import GenerateContentConfig

from dotenv import load_dotenv

load_dotenv()

class MCPClient:
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        
        gemini_api_key = os.getenv("GOOGLE_API_KEY")
        if not gemini_api_key:
            raise ValueError("GOOGLE_API_KEY not found. Please add it to your .env file..")

        self.genai_client = genai.Client(api_key=gemini_api_key)
        self.chat_history: list[types.Content] = []


    async def connect_to_server(self, server_script_path: str):
        """Connect to an MCP server
        
        Args:
            server_script_path: Path to the server script(.py or .js)
        """
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')

        if not (is_python or is_js):
            raise ValueError("Server script must be a .py or .js file")
        
        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env = None
        )

        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio,self.write))


        await self.session.initialize()

        response = await self.session.list_tools()
        tools = response.tools
        print("\nConnected to server with tools:", [tool.name for tool in tools])

        # Converts MCP tools to Gemini format
        self.function_declarations = convert_mcp_tools_to_gemini(tools)

        
    # async def process_query(self, query: str) -> str:
    #     """Process a user query using Gemini and available tools
        
    #     Args:
    #         query (str): The user's input query
        
    #     Returns:
    #         str: The response generated by the Gemini model.
    #     """

    #     messages = types.Content(
    #         role='user',
    #         parts = [types.Part.from_text(text=query)]
    #     )

    #     response = self.genai_client.models.generate_content(
    #         model = 'gemini-2.0-flash-001',
    #         contents=[messages],
    #         config = types.GenerateContentConfig(
    #             tools=self.function_declarations
    #         )
    #     )

    #     final_text = []
    #     assistan_message_content = []

    #     for candidate in response.candidates:
    #         if candidate.content.parts:
    #             for part in candidate.content.parts:
    #                 if isinstance(part, types.Part):
    #                     if part.function_call:

    #                         function_call_part = part
    #                         tool_name = function_call_part.function_call.name
    #                         tool_args = function_call_part.function_call.args


    #                         print(f"\n[Gemini requested tool call: {tool_name} with args {tool_args}]")

    #                         try:
    #                             result = await self.session.call_tool(tool_name, tool_args)
    #                             function_response = {"result": result.content}
    #                         except Exception as e:
    #                             function_response = {"error": str(e)}

    #                         function_response_part = types.Part.from_function_response(
    #                             name = tool_name,
    #                             response=function_response
    #                         )

    #                         function_response_content = types.Content(
    #                             role='tool',
    #                             parts=[function_response_part]
    #                         )

    #                         response = self.genai_client.models.generate_content(
    #                             model = 'gemini-2.0-flash-001',
    #                             contents=[
    #                                 messages,
    #                                 function_call_part,
    #                                 function_response_content,
    #                                 ],
    #                             config = types.GenerateContentConfig(
    #                                 tools=self.function_declarations
    #                             )
    #                         )

    #                         final_text.append(response.candidates[0].content.parts[0].text)
    #                     else:
    #                         final_text.append(part.text)
        
    #     return "\n".join(final_text)

    async def process_query(self, query: str) -> str:
        user_message = types.Content(
            role='user',
            parts=[types.Part.from_text(text=query)]
        )
        self.chat_history.append(user_message)

        response = self.genai_client.models.generate_content(
            model='gemini-2.0-flash-001',
            contents=self.chat_history,
            config=types.GenerateContentConfig(tools=self.function_declarations)
        )

        final_text = []

        for candidate in response.candidates:
            if candidate.content.parts:
                for part in candidate.content.parts:
                    if isinstance(part, types.Part):
                        if part.function_call:
                            tool_name = part.function_call.name
                            tool_args = part.function_call.args

                            print(f"\n[Gemini requested tool call: {tool_name} with args {tool_args}]")

                            try:
                                result = await self.session.call_tool(tool_name, tool_args)
                                function_response = {"result": result.content}
                            except Exception as e:
                                function_response = {"error": str(e)}

                            function_response_part = types.Part.from_function_response(
                                name=tool_name,
                                response=function_response
                            )

                            function_response_content = types.Content(
                                role='tool',
                                parts=[function_response_part]
                            )

                            # Add both the function call and response to history
                            self.chat_history.append(part)
                            self.chat_history.append(function_response_content)

                            # Continue the chat with full history including function response
                            response = self.genai_client.models.generate_content(
                                model='gemini-2.0-flash-001',
                                contents=self.chat_history,
                                config=types.GenerateContentConfig(tools=self.function_declarations)
                            )

                            response_text = response.candidates[0].content.parts[0].text
                            final_text.append(response_text)

                            # Save assistant's response to history
                            assistant_message = types.Content(
                                role='model',
                                parts=[types.Part.from_text(text=response_text)]
                            )
                            self.chat_history.append(assistant_message)

                        else:
                            text = part.text
                            final_text.append(text)
                            # Save assistant's response to history
                            assistant_message = types.Content(
                                role='model',
                                parts=[types.Part.from_text(text=text)]
                            )
                            self.chat_history.append(assistant_message)

        return "\n".join(final_text)

    async def chat_loop(self):
        """Run an interactive chat loop"""
        print("\nMCP Client Started!")
        print("Type your queries or 'quit' to exit.")

        while True:
            try:
                query = input("\nQuery: ").strip()

                if query.lower() == "quit":
                    break
                
                response = await self.process_query(query)
                print("\n" + response)
            
            except Exception as e:
                print(f"\nError: {str(e)}")

    async def cleanup(self):
        """Clean up resources"""
        await self.exit_stack.aclose()



def clean_schema(schema):
    """
    Recursively removes 'title' fields from the JSON schema.
    
    Args:
        schema (dict): The schema dictionary.
        
    Returns:
        dict: Cleaned schema without 'title' fields.
    """

    if isinstance(schema, dict):
        schema.pop("title",None)

    if "properties" in schema and isinstance(schema["properties"], dict):
        for key in schema["properties"]:
            schema["properties"][key] = clean_schema(schema["properties"][key])

    return schema



def convert_mcp_tools_to_gemini(mcp_tools):
    """
    Converts MCP tool definitions to the correct format for Gemini API function calling.
    
    Args:
        mcp_tools (list): List of MCP tool objects with 'name', 'description', and 'inputSchema'.
        
    Returns:
    list: List of Gemini Tool objects with properly formatted function declarations.
    """

    gemini_tools = []

    for tool in mcp_tools:

        parameters = clean_schema(tool.inputSchema)

        function_declaration = FunctionDeclaration(
            name = tool.name,
            description = tool.description,
            parameters= parameters
        )

        gemini_tool = Tool(function_declarations=[function_declaration])
        gemini_tools.append(gemini_tool)

    return gemini_tools

async def main():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script")
        sys.exit(1)

    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.cleanup()

    
if __name__ == "__main__":
    asyncio.run(main())